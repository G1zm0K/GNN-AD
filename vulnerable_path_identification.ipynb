{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Directory Most Vulnerable Path Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & globals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from py2neo import Graph\n",
    "import random\n",
    "import torch\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "import json\n",
    "import os\n",
    "from torch_geometric.nn import to_hetero, GAT, SAGEConv\n",
    "from torch_geometric.explain import Explanation\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection details\n",
    "graph = Graph(\"http://localhost:7474\", auth=(\"neo4j\", \"bloodhoundcommunityedition\"))\n",
    "\n",
    "# Object types and their corresponding properties\n",
    "object_types_and_properties = {\n",
    "    'Domain': ['name', 'objectid', 'highvalue'],\n",
    "    'User': ['name', 'objectid', 'admincount', 'dontreqpreauth', 'pwdneverexpires', 'hasspn', 'highvalue', 'savedcredentials',\n",
    "             'passwordnotreqd', 'pwdlastset', 'lastlogon', 'unconstraineddelegation', 'enabled', 'sensitive'],\n",
    "    'Computer': ['name', 'objectid', 'operatingsystem', 'enabled', 'haslaps', 'highvalue', 'lastlogontimestamp', \n",
    "                 'pwdlastset', 'unconstraineddelegation', 'privesc', 'creddump', \n",
    "                 'exploitable'],\n",
    "    'Group': ['name', 'objectid', 'highvalue', 'admincount'],\n",
    "    'OU': ['name', 'objectid', 'highvalue', 'blocksInheritance'],\n",
    "    'GPO': ['name', 'objectid', 'exploitable'],\n",
    "    'Container': ['name', 'objectid', 'highvalue']\n",
    "}\n",
    "\n",
    "# Relationship types\n",
    "relationship_types = [\n",
    "    'AddMember',\n",
    "    'AddSelf',\n",
    "    'AdminTo',\n",
    "    'AllExtendedRights',\n",
    "    'AllowedToAct',\n",
    "    'AllowedToDelegate',\n",
    "    'CanPSRemote',\n",
    "    'CanRDP',\n",
    "    'Contains',\n",
    "    'ExecuteDCOM',\n",
    "    'ForceChangePassword',\n",
    "    'GenericAll',\n",
    "    'GenericWrite',\n",
    "    'GetChanges',\n",
    "    'GetChangesAll',\n",
    "    'GpLink',\n",
    "    'HasSession',\n",
    "    'MemberOf',\n",
    "    'Owns',\n",
    "    'ReadLAPSPassword',\n",
    "    'SQLAdmin',\n",
    "    'WriteDacl',\n",
    "    'WriteOwner'\n",
    "]\n",
    "\n",
    "# OS possibilities\n",
    "global_os_categories = ['Windows Server 2003 Enterprise Edition', 'Windows Server 2008 Datacenter', 'Windows Server 2008 Enterprise', \n",
    "                        'Windows Server 2008 R2 Datacenter', 'Windows Server 2008 R2 Enterprise', 'Windows Server 2008 R2 Standard', \n",
    "                        'Windows Server 2008 Standard', 'Windows Server 2012 Datacenter', 'Windows Server 2012 R2 Datacenter', \n",
    "                        'Windows Server 2012 R2 Standard', 'Windows Server 2012 Standard', 'Windows Server 2016 Datacenter', \n",
    "                        'Windows Server 2016 Standard']\n",
    "\n",
    "# Object property types\n",
    "object_property_types = {\n",
    "    \"Domain\": {\n",
    "        \"Name\": \"string\",\n",
    "        \"Objectid\": \"string\",\n",
    "        \"Highvalue\": \"boolean\"\n",
    "    },\n",
    "    \"User\": {\n",
    "        \"Name\": \"string\",\n",
    "        \"Objectid\": \"string\",\n",
    "        \"Admincount\": \"boolean\",\n",
    "        \"Dontreqpreauth\": \"boolean\",\n",
    "        \"Pwdneverexpires\": \"boolean\",\n",
    "        \"Hasspn\": \"boolean\",\n",
    "        \"Highvalue\": \"boolean\",\n",
    "        \"Savedcredentials\": \"boolean\",\n",
    "        \"Passwordnotreqd\": \"boolean\",\n",
    "        \"Pwdlastset\": \"numerical\",\n",
    "        \"Lastlogon\": \"numerical\",\n",
    "        \"Unconstraineddelegation\": \"boolean\",\n",
    "        \"Enabled\": \"boolean\",\n",
    "        \"Sensitive\": \"boolean\"\n",
    "    },\n",
    "    \"Computer\": {\n",
    "        \"Name\": \"string\",\n",
    "        \"Objectid\": \"string\",\n",
    "        \"Operatingsystem\": \"categorical\",\n",
    "        \"Enabled\": \"boolean\",\n",
    "        \"Haslaps\": \"boolean\",\n",
    "        \"Highvalue\": \"boolean\",\n",
    "        \"Lastlogontimestamp\": \"numerical\",\n",
    "        \"Pwdlastset\": \"numerical\",\n",
    "        \"Unconstraineddelegation\": \"boolean\",\n",
    "        \"Privesc\": \"boolean\",\n",
    "        \"Creddump\": \"boolean\",\n",
    "        \"Exploitable\": \"boolean\"\n",
    "    },\n",
    "    \"Group\": {\n",
    "        \"Name\": \"string\",\n",
    "        \"Objectid\": \"string\",\n",
    "        \"Highvalue\": \"boolean\",\n",
    "        \"Admincount\": \"boolean\"\n",
    "    },\n",
    "    \"OU\": {\n",
    "        \"Name\": \"string\",\n",
    "        \"Objectid\": \"string\",\n",
    "        \"Highvalue\": \"boolean\",\n",
    "        \"Blocksinheritance\": \"boolean\"\n",
    "    },\n",
    "    \"GPO\": {\n",
    "        \"Name\": \"string\",\n",
    "        \"Objectid\": \"string\",\n",
    "        \"Exploitable\": \"boolean\"\n",
    "    },\n",
    "    \"Container\": {\n",
    "        \"Name\": \"string\",\n",
    "        \"Objectid\": \"string\",\n",
    "        \"Highvalue\": \"boolean\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Torch print options\n",
    "torch.set_printoptions(threshold=float('inf'), linewidth=1000)\n",
    "#torch.set_printoptions(profile=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for handling graph database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_neo4j_database(session):\n",
    "    # Delete nodes and edges with batching into 10k objects - From DBCreator\n",
    "    total = 1\n",
    "    while total > 0:\n",
    "        result = session.run(\n",
    "            \"MATCH (n) WITH n LIMIT 10000 DETACH DELETE n RETURN count(n)\")\n",
    "        for r in result:\n",
    "            total = int(r['count(n)'])\n",
    "    session.run(\"CALL apoc.schema.assert({},{},true);\")\n",
    "    \n",
    "        # Remove constraint - From DBCreator\n",
    "    for constraint in session.run(\"SHOW CONSTRAINTS\"):\n",
    "        session.run(\"DROP CONSTRAINT {}\".format(constraint['name']))\n",
    "\n",
    "    icount = session.run(\n",
    "        \"SHOW INDEXES YIELD name RETURN count(*)\")\n",
    "    for r in icount:\n",
    "        ic = int(r['count(*)'])\n",
    "            \n",
    "    while ic >0:\n",
    "    \n",
    "        showall = session.run(\n",
    "            \"SHOW INDEXES\")\n",
    "        for record in showall:\n",
    "            name = (record['name'])\n",
    "            session.run(\"DROP INDEX {}\".format(name))\n",
    "        ic = 0\n",
    "        \n",
    "    # Setting constraints\n",
    "    constraints = [\n",
    "            \"CREATE CONSTRAINT FOR (n:Base) REQUIRE n.neo4jImportId IS UNIQUE;\",\n",
    "            \"CREATE CONSTRAINT FOR (n:Domain) REQUIRE n.neo4jImportId IS UNIQUE;\",\n",
    "            \"CREATE CONSTRAINT FOR (n:Computer) REQUIRE n.neo4jImportId IS UNIQUE;\",\n",
    "            \"CREATE CONSTRAINT FOR (n:User) REQUIRE n.neo4jImportId IS UNIQUE;\",\n",
    "            \"CREATE CONSTRAINT FOR (n:OU) REQUIRE n.neo4jImportId IS UNIQUE;\",\n",
    "            \"CREATE CONSTRAINT FOR (n:GPO) REQUIRE n.neo4jImportId IS UNIQUE;\",\n",
    "            \"CREATE CONSTRAINT FOR (n:Compromised) REQUIRE n.neo4jImportId IS UNIQUE;\",\n",
    "            \"CREATE CONSTRAINT FOR (n:Group) REQUIRE n.neo4jImportId IS UNIQUE;\",\n",
    "            \"CREATE CONSTRAINT FOR (n:Container) REQUIRE n.neo4jImportId IS UNIQUE;\",\n",
    "    ]\n",
    "\n",
    "    for constraint in constraints:\n",
    "        try:\n",
    "            session.run(constraint)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    session.run(\"match (a) -[r] -> () delete a, r\")\n",
    "    session.run(\"match (a) delete a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_from_json(session, file_path):\n",
    "    \"\"\"\n",
    "    Loads a graph from a JSON file into Neo4j.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        query = f\"PROFILE CALL apoc.periodic.iterate(\\\"CALL apoc.import.json('{file_path}')\\\", \\\"RETURN 1\\\", {{batchSize:1000}})\"\n",
    "        session.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for extracting features and creating dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract features from neo4j database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from the Neo4j database for a specific object type and returns a Pandas DataFrame.\n",
    "def extract_features(graph, labels, properties):\n",
    "\n",
    "    # Create the RETURN clause dynamically based on the provided properties\n",
    "    return_clause = \", \".join([f\"n.{prop} AS node_{prop}\" for prop in properties])\n",
    "\n",
    "    # Define the Cypher query with labels and properties\n",
    "    query = f\"\"\"\n",
    "    MATCH (n:{labels})\n",
    "    RETURN \n",
    "        id(n) AS node_id, \n",
    "        {return_clause}\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query and store the results in a Pandas DataFrame\n",
    "    result = graph.run(query)\n",
    "    df = pd.DataFrame(result)\n",
    "\n",
    "    if df.empty:  # Check if the DataFrame is empty\n",
    "        df = pd.DataFrame(columns=['Node ID'] + [prop.title() for prop in properties]) \n",
    "\n",
    "    # Add headers to the DataFrame (adjust based on properties)\n",
    "    df.columns = ['Node ID'] + [prop.title() for prop in properties]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_properties(graph, label):\n",
    "    query = f\"\"\"\n",
    "    MATCH (n:{label})\n",
    "    WITH keys(n) AS keys\n",
    "    UNWIND keys AS key\n",
    "    RETURN DISTINCT key\n",
    "    \"\"\"\n",
    "    result = graph.run(query)\n",
    "    return [record[\"key\"] for record in result]\n",
    "\n",
    "all_possible_object_types_and_properties = {\n",
    "    label: get_node_properties(graph, label) \n",
    "    for label in ['Domain', 'User', 'Computer', 'Group', 'GPO', 'Container']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract relationships from the Neo4j database and returns a Pandas DataFrame.\n",
    "def extract_relationships(graph, rel_types):\n",
    "    \n",
    "    # List to store DataFrames for each relationship type\n",
    "    dfs = []\n",
    "\n",
    "    for rel_type in rel_types:\n",
    "        # Define the Cypher query with dynamic relationship type\n",
    "        query = f\"\"\"\n",
    "        MATCH (source)-[r:{rel_type}]->(target)\n",
    "        RETURN \n",
    "            id(source) AS source_id,\n",
    "            id(target) AS target_id,\n",
    "            TYPE(r) AS relationship_type\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the query and store the results in a Pandas DataFrame\n",
    "        result = graph.run(query)\n",
    "        df = pd.DataFrame(result)\n",
    "        \n",
    "        if not df.empty:\n",
    "\n",
    "            # Add headers to the DataFrame\n",
    "            df.columns = ['Source ID', 'Target ID', 'Relationship Type']\n",
    "\n",
    "            dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframes(dfs):\n",
    "    for object_name in dfs:\n",
    "        for property in dfs[object_name].columns:\n",
    "            # Take first element if it is a list\n",
    "            dfs[object_name][property] = dfs[object_name][property].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "            # Set boolean to False if null\n",
    "            dfs[object_name][property] = dfs[object_name][property].apply(lambda x: False if x == \"null\" else x)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns (object_dfs):\n",
    "    for df_name in object_dfs:\n",
    "        # Add score column\n",
    "        object_dfs[df_name]['Score'] = 0\n",
    "\n",
    "        # Add source/target node column\n",
    "        object_dfs[df_name]['Source/Target'] = 0\n",
    "\n",
    "        #Add shortest path coumn\n",
    "        object_dfs[df_name]['Shortest Path'] = 0\n",
    "    return object_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns (object_dfs):\n",
    "    for df_name in object_dfs:\n",
    "        # Add score column\n",
    "        object_dfs[df_name]['Score'] = 0\n",
    "\n",
    "        # Add source/target node column\n",
    "        object_dfs[df_name]['Source/Target'] = 0\n",
    "\n",
    "        #Add shortest path coumn\n",
    "        object_dfs[df_name]['Shortest Path'] = 0\n",
    "    return object_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to scores\n",
    "# For now generated by Guiseppe paper/own insight, assign more precise scores later\n",
    "\n",
    "features = {}\n",
    "\n",
    "# Domain features\n",
    "features['Domain'] = {\n",
    "    \"Highvalue\": {True: 10, False: 0} # A compromised domain is extremely high value.\n",
    "}\n",
    "\n",
    "# Computer features\n",
    "features['Computer'] = {\n",
    "    \"Operatingsystem\": {\n",
    "        \"Windows Server 2003 Enterprise Edition\": 29,\n",
    "        \"Windows XP Professional Service Pack 3\": 29,\n",
    "        \"Windows Server 2008 Standard\": 27,\n",
    "        \"Windows Server 2008 Datacenter\": 27,\n",
    "        \"Windows Server 2008 Enterprise\": 27,\n",
    "        \"Windows 7 Professional Service Pack 1\": 22,\n",
    "        \"Windows 7 Ultimate Service Pack 1\": 22,\n",
    "        \"Windows 7 Enterprise Service Pack 1\": 22,\n",
    "        \"Windows Server 2008 R2 Standard\": 20,\n",
    "        \"Windows Server 2008 R2 Datacenter\": 20,\n",
    "        \"Windows Server 2008 R2 Enterprise\": 20,\n",
    "        \"Windows Server 2012 Standard\": 17,\n",
    "        \"Windows Server 2012 Datacenter\": 17,\n",
    "        \"Windows Server 2012 R2 Standard\": 14, \n",
    "        \"Windows Server 2012 R2 Datacenter\": 14,\n",
    "        \"Windows Server 2016 Standard\": 10,\n",
    "        \"Windows Server 2016 Datacenter\": 10,\n",
    "        \"Windows 10 Pro\": 7,\n",
    "        \"Windows 10 Enterprise\": 3,\n",
    "    },\n",
    "    \"Enabled\": {True: 1, False: 0},\n",
    "    \"Haslaps\": {True: 0, False: 1},\n",
    "    \"Highvalue\": {True: 5, False: 0},\n",
    "    \"Lastlogontimestamp\": lambda x: 1 if x == 0.0 else 0,  # Higher score if never logged on\n",
    "    \"Pwdlastset\": lambda x: 1 if x == 0.0 or x == -1.0 else 0,  # Higher score if never set or unknown\n",
    "    \"Unconstraineddelegation\": {True: 5, False: 0},\n",
    "    \"Privesc\": {True: 10, False: 0},\n",
    "    \"Creddump\": {True: 7, False: 0},\n",
    "    \"Exploitable\": {True: 10, False: 0},\n",
    "}\n",
    "\n",
    "# GPO features\n",
    "features['GPO'] = {\n",
    "    \"Exploitable\": {True: 10, False: 0}\n",
    "}\n",
    "\n",
    "# Group features\n",
    "features['Group'] = {\n",
    "    \"Highvalue\": {True: 10, False: 0},\n",
    "    \"Admincount\": {True: 10, False: 0}\n",
    "}\n",
    "\n",
    "# OU features\n",
    "features['OU'] = {\n",
    "    \"Highvalue\": {True: 10, False: 0},\n",
    "    \"Blocksinheritance\": {True: 10, False: 0}\n",
    "}\n",
    "\n",
    "\n",
    "# User features\n",
    "features['User'] = {\n",
    "    \"Admincount\": {True: 5, False: 0},\n",
    "    \"Dontreqpreauth\": {True: 5, False: 0},\n",
    "    \"Pwdneverexpires\": {True: 3, False: 0},\n",
    "    \"Hasspn\": {True: 5, False: 0},\n",
    "    \"Highvalue\": {True: 5, False: 0},\n",
    "    \"Savedcredentials\": {True: 3, False: 0},\n",
    "    \"Passwordnotreqd\": {True: 10, False: 0},\n",
    "    \"Pwdlastset\": lambda x: 3 if x == 0.0 or x == -1.0 else 0,  # Higher score if never set or unknown\n",
    "    \"Lastlogon\": lambda x: 1 if x == 0.0 or x == -1.0 else 0,  # Higher score if never logged on or unknown\n",
    "    \"Unconstraineddelegation\": {True: 5, False: 0},\n",
    "    \"Enabled\": {True: 1, False: 0},\n",
    "    \"Sensitive\": {True: 3, False: 0},\n",
    "}\n",
    "\n",
    "# Container features\n",
    "features['Container'] = {\n",
    "    \"Highvalue\": {True: 5, False: 0} # Containers are less critical than domains or OUs but still can hold sensitive objects.\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate and add scores for each of the objects\n",
    "def calculate_and_add_scores(object_dfs):\n",
    "    # For every dataframe\n",
    "    for df_name in object_dfs:\n",
    "        # For every row (node) in dataframe\n",
    "        for i in object_dfs[df_name].index:\n",
    "            score = 0\n",
    "            # For every feature of the node (except name and id)\n",
    "            for feature, values in features[df_name].items():\n",
    "                feature_value = object_dfs[df_name].loc[i, feature]\n",
    "\n",
    "                # Check if lambda function\n",
    "                if callable(values):\n",
    "                    score += values(feature_value)\n",
    "                # Check if dictionary\n",
    "                elif isinstance(values, dict):\n",
    "                    # Check if list\n",
    "                    if isinstance(feature_value, list):\n",
    "                        for item in feature_value:\n",
    "                            if item in values:\n",
    "                                score += values[item]\n",
    "                    # Check if normal value\n",
    "                    elif feature_value in values:\n",
    "                        score += values[feature_value]\n",
    "\n",
    "            # Assign score\n",
    "            object_dfs[df_name].loc[i, 'Score'] = score\n",
    "    return object_dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_scores = {\n",
    "    \"Computer\": {\n",
    "        \"MemberOf\": 15,\n",
    "        \"AdminTo\": 2,\n",
    "        \"HasSession\": 2,\n",
    "        \"CanRDP\": 2,\n",
    "        \"CanPSRemote\": 2,\n",
    "        \"ExecuteDCOM\": 2,\n",
    "        \"AllowedToAct\": 5,\n",
    "        \"AllowedToDelegate\": 5,\n",
    "        \"Contains\": 8,\n",
    "        \"SQLAdmin\": 10,\n",
    "        \"WriteDacl\": 10,        \n",
    "        \"WriteOwner\": 10,       \n",
    "    },\n",
    "    \"Domain\": {\n",
    "        \"TrustedBy\": 3,\n",
    "        \"Contains\": 20,\n",
    "        \"AddSelf\": 8    \n",
    "    },\n",
    "    \"GPO\": {\n",
    "        \"Contains\": 8,\n",
    "        \"GPLink\": 4      \n",
    "    },\n",
    "    \"Group\": {\n",
    "        \"MemberOf\": 30,\n",
    "        \"AdminTo\": 10,\n",
    "        \"CanRDP\": 2,\n",
    "        \"CanPSRemote\": 2,\n",
    "        \"ExecuteDCOM\": 2,\n",
    "        \"Contains\": 20,\n",
    "        \"AddMember\": 8, \n",
    "        \"GenericAll\": 10,   \n",
    "    },\n",
    "    \"OU\": {\n",
    "        \"Contains\": 15\n",
    "    },\n",
    "    \"User\": {\n",
    "        \"MemberOf\": 35,\n",
    "        \"AdminTo\": 10,\n",
    "        \"HasSession\": 3,\n",
    "        \"CanRDP\": 5,\n",
    "        \"CanPSRemote\": 5,\n",
    "        \"ExecuteDCOM\": 5,\n",
    "        \"AllowedToAct\": 5,\n",
    "        \"AllowedToDelegate\": 5, \n",
    "        \"Contains\": 20,\n",
    "        \"ReadLAPSPassword\": 10,\n",
    "        \"ALLExtendedRights\": 8,\n",
    "        \"GenericWrite\": 8,\n",
    "        \"Owns\": 10, \n",
    "        \"ForceChangePassword\": 8,\n",
    "        \"GetChangesAll\": 6,\n",
    "        \"GetChanges\": 6          \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get relationship score based on the table\n",
    "def get_relationship_score(source_type, relationship_type):\n",
    "    if source_type in relationship_scores and relationship_type in relationship_scores[source_type]:\n",
    "        score = relationship_scores[source_type][relationship_type]\n",
    "        return score\n",
    "    else:\n",
    "        # print(f\"Can't find {relationship_type}\")\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relationship scores to node scores\n",
    "def add_relationship_scores(object_dfs, df_rels):\n",
    "    for df_name in object_dfs:\n",
    "        for i in object_dfs[df_name].index:\n",
    "            source_id = object_dfs[df_name].loc[i, 'Node ID']\n",
    "            outgoing_relationships = df_rels[df_rels['Source ID'] == source_id]\n",
    "\n",
    "            for _, row in outgoing_relationships.iterrows():\n",
    "                relationship_type = row['Relationship Type']\n",
    "                relationship_score = get_relationship_score(df_name, relationship_type)\n",
    "                object_dfs[df_name].loc[i, 'Score'] += relationship_score\n",
    "    return object_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map name to node id\n",
    "def get_node_name(object_dfs, node_id, dataframes):\n",
    "  # Iterate through each DataFrame\n",
    "  for df_name in dataframes:\n",
    "    # Look for node id\n",
    "    node = object_dfs[df_name][object_dfs[df_name]['Node ID'] == node_id]\n",
    "    if not node.empty:\n",
    "      # If found, return the corresponding name\n",
    "      return node['Name'].iloc[0]  \n",
    "  # If not found in any DataFrame, return None\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node and relationship dataframes\n",
    "def create_dataframes(object_dfs, df_rels):\n",
    "    # Initialize empty list\n",
    "    extracted_data = []\n",
    "\n",
    "    # Iterate through each DataFrame\n",
    "    for df_name in object_dfs:\n",
    "        # Extract the 'Node ID' and 'Score' columns\n",
    "        extracted_df = object_dfs[df_name][['Node ID', 'Score', 'Source/Target', 'Shortest Path']].copy()\n",
    "        extracted_data.append(extracted_df)\n",
    "\n",
    "    # Concatenate all extracted DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(extracted_data, ignore_index=True)\n",
    "\n",
    "    # Get all unique Node IDs from combined_df\n",
    "    valid_nodes = combined_df['Node ID']\n",
    "\n",
    "    # Filter df_rels to keep only relationships between valid nodes\n",
    "    df_rels_filtered = df_rels[\n",
    "        df_rels['Source ID'].isin(valid_nodes) & df_rels['Target ID'].isin(valid_nodes)\n",
    "    ].copy()\n",
    "    return combined_df, df_rels_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shortest_path(combined_df, df_rels_filtered, object_dfs):\n",
    "# HIER GEBLEVEN!\n",
    "  # Create NetworkX graph\n",
    "  nx_graph = nx.DiGraph()\n",
    "\n",
    "  # Add nodes with 'Score' as weight\n",
    "  for _, row in combined_df.iterrows():\n",
    "      nx_graph.add_node(row['Node ID'], weight=1/(row['Score']+1e-10))\n",
    "\n",
    "  # Add edges\n",
    "  for _, row in df_rels_filtered.iterrows():\n",
    "      nx_graph.add_edge(row['Source ID'], row['Target ID'])\n",
    "\n",
    "  shortest_path_found = False\n",
    "  while(True):\n",
    "    # Select random user node\n",
    "    source_node = int(object_dfs['User'][object_dfs['User']['Objectid'].str.endswith(str(random.randint(10,99)))]['Node ID'].iloc[0])\n",
    "    # Select domain admin node\n",
    "    target_node = int(object_dfs['Group'][object_dfs['Group']['Objectid'].str.endswith('-512')]['Node ID'].iloc[0])\n",
    "\n",
    "    # Run Dijkstra\n",
    "    try:\n",
    "        shortest_path = nx.dijkstra_path(nx_graph, source=source_node, target=target_node, weight='weight')\n",
    "        break\n",
    "    except nx.NetworkXNoPath:\n",
    "        print(f\"No path found between {source_node} and {target_node}\")\n",
    "  return source_node, target_node, shortest_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add shortest path to node features\n",
    "\n",
    "# For every dataframe\n",
    "def add_shortest_path(object_dfs, shortest_path, target_node, source_node):\n",
    "    for df_name in object_dfs:\n",
    "        # For every row (node) in dataframe\n",
    "        for i in object_dfs[df_name].index:\n",
    "            if object_dfs[df_name].loc[i, 'Node ID'] in shortest_path:\n",
    "                object_dfs[df_name].loc[i, 'Shortest Path'] = 1\n",
    "            if object_dfs[df_name].loc[i, 'Node ID'] == source_node or object_dfs[df_name].loc[i, 'Node ID'] == target_node:\n",
    "                object_dfs[df_name].loc[i, 'Source/Target'] = 1\n",
    "    return object_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Homogenous PyG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensors(df_rels_filtered, combined_df):\n",
    "    node_id_to_index = {node_id: index for index, node_id in enumerate(combined_df['Node ID'])}\n",
    "    df_rels_filtered.loc[:, 'Source Index'] = df_rels_filtered['Source ID'].map(node_id_to_index)\n",
    "    df_rels_filtered.loc[:, 'Target Index'] = df_rels_filtered['Target ID'].map(node_id_to_index)\n",
    "\n",
    "    target_nodes_tensor = torch.from_numpy(df_rels_filtered['Target Index'].values)\n",
    "    source_nodes_tensor = torch.from_numpy(df_rels_filtered['Source Index'].values)\n",
    "    edge_index = torch.stack((source_nodes_tensor,target_nodes_tensor))\n",
    "    df = combined_df.sort_values('Node ID')\n",
    "\n",
    "    # Extract features\n",
    "    score_tensor = torch.tensor(df['Score'].values, dtype=torch.float).unsqueeze(1)\n",
    "    source_target_tensor = torch.tensor(df['Source/Target'].values, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "    x = torch.stack([score_tensor,source_target_tensor], dim=1)\n",
    "    y = torch.tensor(df['Shortest Path'].values, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "    return df, x, y, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"http://localhost:7474\", auth=(\"neo4j\", \"bloodhoundcommunityedition\"))\n",
    "data_dir = \"\"\n",
    "data = []\n",
    "\n",
    "#Main generation function\n",
    "print(\"===== Start =====\")\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        print(\"----- Starting process for new graph -----\")\n",
    "        print(f\"Now processing: {filename} \")\n",
    "\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        print(\"Clearing database\")\n",
    "        clear_neo4j_database(graph)\n",
    "\n",
    "        print(\"Loading json file\")\n",
    "        load_graph_from_json(graph, file_path)\n",
    "\n",
    "        print(\"Extracting features\")\n",
    "        object_dfs = {}\n",
    "        for object_type, properties in object_types_and_properties.items():\n",
    "            # object_dfs[object_type] = extract_features(graph, object_type, properties).dropna()\n",
    "            imputer = SimpleImputer(strategy='most_frequent')  # Or 'median', 'most_frequent'\n",
    "            object_dfs[object_type] = extract_features(graph, object_type, properties)\n",
    "            for property in object_dfs[object_type].columns:\n",
    "                # Take first element if it is a list\n",
    "                object_dfs[object_type][property] = object_dfs[object_type][property].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "                # Set boolean to False if null\n",
    "                object_dfs[object_type][property] = object_dfs[object_type][property].apply(lambda x: False if x == \"null\" or x is None else x) \n",
    "            object_dfs[object_type][:] = imputer.fit_transform(object_dfs[object_type])  # Impute in place\n",
    "        \n",
    "        print(\"Adding additional columns\")        \n",
    "        object_dfs = add_columns(object_dfs)\n",
    "\n",
    "        print(\"Extracting relationships\")\n",
    "        relationship_df = extract_relationships(graph, relationship_types)\n",
    "        relationship_df.to_csv('relationship_features.csv', index=False)\n",
    "\n",
    "        print(\"Calculating and adding scores\")\n",
    "        object_dfs = calculate_and_add_scores(object_dfs)\n",
    "        object_dfs = add_relationship_scores(object_dfs, relationship_df)\n",
    "\n",
    "        print(\"Computing shortest path\")\n",
    "        combined_df, df_rels_filtered = create_dataframes(object_dfs, relationship_df)\n",
    "        source_node, target_node, shortest_path = calculate_shortest_path(combined_df, df_rels_filtered, object_dfs)\n",
    "\n",
    "        print(\"Adding shortest path to dataframes\")\n",
    "        object_dfs = add_shortest_path(object_dfs, shortest_path, target_node, source_node)\n",
    "        combined_df, df_rels_filtered = create_dataframes(object_dfs, relationship_df)\n",
    "\n",
    "        print(\"Convert to tensors and add to dataset\")\n",
    "        df, x, y, edge_index = convert_to_tensors(df_rels_filtered, combined_df)\n",
    "        data.append(Data(x=x.squeeze(), edge_index=edge_index, y=y))\n",
    "\n",
    "torch.save(data, \"dataset_spi.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"dataset_spi.pt\")\n",
    "print(f'Number of graphs: {len(data)}')\n",
    "print(f'Number of features: {data[0].num_features}')\n",
    "print(f'Number of classes: {len(torch.unique(data[0].y))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)  # For reproducibility\n",
    "num_graphs = len(data)\n",
    "shuffled_indices = torch.randperm(num_graphs)\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Calculate split sizes\n",
    "train_size = int(train_ratio * num_graphs)\n",
    "val_size = int(val_ratio * num_graphs)\n",
    "test_size = num_graphs - train_size - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset = [data[i] for i in shuffled_indices[:train_size]]\n",
    "val_dataset = [data[i] for i in shuffled_indices[train_size:train_size + val_size]]\n",
    "test_dataset = [data[i] for i in shuffled_indices[train_size + val_size:]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation\n",
    "        self.lin = torch.nn.Linear(in_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Step 1: Linearly transform node feature matrix\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 2: Propagate messages to destination nodes\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(2, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin_final = torch.nn.Linear(hidden_channels, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Convolutional operations\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        # Final linear transformation\n",
    "        x = self.lin_final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import add_self_loops\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):  # Renamed hidden_channels to out_channels for clarity\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        x = self.lin(x)\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers, out_channels):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(GCNConv(in_channels, hidden_channels))  # First layer\n",
    "\n",
    "        for _ in range(num_layers - 2): # Hidden layers\n",
    "            self.layers.append(GCNConv(hidden_channels, hidden_channels))\n",
    "\n",
    "        self.layers.append(GCNConv(hidden_channels, out_channels))  # Last layer\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.layers):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.layers) - 1:\n",
    "                x = F.relu(x)\n",
    "                x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def plot_learning_curves(history, params, save_dir='learning_curve_macrof1'):\n",
    "    \"\"\"Plot and save learning curves for a parameter combination\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Loss subplot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_losses'], label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Accuracy subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_accuracies'], label='Training Accuracy')\n",
    "    plt.plot(history['val_accuracies'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Create title with parameters\n",
    "    plt.suptitle(f'Layers: {params[\"num_layers\"]}, Hidden: {params[\"hidden_channels\"]}, LR: {params[\"learning_rate\"]}')\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save plot\n",
    "    filename = f'layers_{params[\"num_layers\"]}_hidden_{params[\"hidden_channels\"]}_lr_{params[\"learning_rate\"]}.png'\n",
    "    plt.savefig(os.path.join(save_dir, filename), bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def train_model(model, train_dataset, val_dataset, learning_rate, num_epochs=50, warmup_epochs=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    weights = torch.tensor([0.00035, 0.1])\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "    \n",
    "    # Track best metrics (initialize with worst possible values)\n",
    "    best_metrics = {\n",
    "        'train_loss': float('inf'),\n",
    "        'train_acc': 0,\n",
    "        'val_acc': 0,\n",
    "        'val_f1': 0,\n",
    "        'epoch': 0,\n",
    "        'is_warmup': True  # Flag to indicate if we're still in warmup period\n",
    "    }\n",
    "    \n",
    "    # History tracking\n",
    "    history = {\n",
    "        'train_losses': [],\n",
    "        'train_accuracies': [],\n",
    "        'val_accuracies': [],\n",
    "        'val_f1_scores': [],\n",
    "        'crs' : []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for i in range(len(train_dataset)):\n",
    "            data_object = train_dataset[i]\n",
    "            out = model(data_object.x, data_object.edge_index)\n",
    "            optimizer.zero_grad()\n",
    "            y = data_object.y.long().squeeze()\n",
    "            \n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            pred_train = out.argmax(dim=1)\n",
    "            correct_train += (pred_train == y).sum().item()\n",
    "            total_train += y.numel()\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        train_loss = epoch_loss / len(train_dataset)\n",
    "        train_acc = correct_train / total_train\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(len(val_dataset)):\n",
    "                data_object = val_dataset[i]\n",
    "                out = model(data_object.x, data_object.edge_index)\n",
    "                y = data_object.y.long().squeeze()\n",
    "                \n",
    "                pred_val = out.argmax(dim=1)\n",
    "                correct_val += (pred_val == y).sum().item()\n",
    "                total_val += y.numel()\n",
    "                \n",
    "                val_predictions.extend(pred_val.cpu().numpy())\n",
    "                val_labels.extend(y.cpu().numpy())\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        val_acc = correct_val / total_val\n",
    "        val_f1 = f1_score(val_labels, val_predictions, average='macro')\n",
    "        # Calculate classification report (includes precision, recall, F1-score)\n",
    "        target_names = ['Not part of path', 'Part of path']  # Adjust class names as needed\n",
    "        cr = classification_report(val_labels, val_predictions, target_names=target_names, zero_division=0)\n",
    "        \n",
    "        # Store history\n",
    "        history['train_losses'].append(train_loss)\n",
    "        history['train_accuracies'].append(train_acc)\n",
    "        history['val_accuracies'].append(val_acc)\n",
    "        history['val_f1_scores'].append(val_f1)\n",
    "        history['crs'].append(cr)\n",
    "        \n",
    "        # Update best metrics only after warmup period\n",
    "        if epoch >= warmup_epochs:\n",
    "            if best_metrics['is_warmup']:\n",
    "                # First update after warmup - set initial \"best\" values\n",
    "                best_metrics = {\n",
    "                    'train_loss': train_loss,\n",
    "                    'train_acc': train_acc,\n",
    "                    'val_acc': val_acc,\n",
    "                    'val_f1': val_f1,\n",
    "                    'epoch': epoch,\n",
    "                    'is_warmup': False,\n",
    "                    'cr': cr\n",
    "                }\n",
    "            else:\n",
    "                # Normal updates after warmup\n",
    "                if val_f1 > best_metrics['val_f1']:\n",
    "                    best_metrics['train_loss'] = train_loss\n",
    "                    best_metrics['train_acc'] = train_acc\n",
    "                    best_metrics['val_acc'] = val_acc\n",
    "                    best_metrics['val_f1'] = val_f1\n",
    "                    best_metrics['epoch'] = epoch\n",
    "                    best_metrics['cr'] = cr\n",
    "        \n",
    "        # Print progress every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "            print(f\"Val - Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
    "            \n",
    "    return best_metrics, history\n",
    "\n",
    "def grid_search(train_dataset, val_dataset, in_channels, out_channels, warmup_epochs=10):\n",
    "    param_grid = {\n",
    "        'num_layers': [1, 2, 3],\n",
    "        'hidden_channels': [16, 32, 64],\n",
    "        'learning_rate': [0.0001, 0.001, 0.01]\n",
    "    }\n",
    "    \n",
    "    param_combinations = list(itertools.product(\n",
    "        param_grid['num_layers'],\n",
    "        param_grid['hidden_channels'],\n",
    "        param_grid['learning_rate']\n",
    "    ))\n",
    "    \n",
    "    results = []\n",
    "    best_overall = {\n",
    "        'train_loss': float('inf'),\n",
    "        'train_acc': 0,\n",
    "        'val_acc': 0,\n",
    "        'val_f1': 0,\n",
    "        'params': None,\n",
    "        'model': None\n",
    "    }\n",
    "    \n",
    "    total_combinations = len(param_combinations)\n",
    "    \n",
    "    for idx, (num_layers, hidden_channels, lr) in enumerate(param_combinations, 1):\n",
    "        print(f\"\\nTesting combination {idx}/{total_combinations}:\")\n",
    "        print(f\"Layers: {num_layers}, Hidden Channels: {hidden_channels}, Learning Rate: {lr}\")\n",
    "        \n",
    "        model = GCN(in_channels, hidden_channels, num_layers, out_channels)\n",
    "        best_metrics, history = train_model(\n",
    "            model,\n",
    "            train_dataset,\n",
    "            val_dataset,\n",
    "            learning_rate=lr,\n",
    "            warmup_epochs=warmup_epochs\n",
    "        )\n",
    "        \n",
    "        # Create parameter dictionary for current combination\n",
    "        current_params = {\n",
    "            'num_layers': num_layers,\n",
    "            'hidden_channels': hidden_channels,\n",
    "            'learning_rate': lr,\n",
    "            'train_loss': best_metrics['train_loss'],\n",
    "            'train_acc': best_metrics['train_acc'],\n",
    "            'val_acc': best_metrics['val_acc'],\n",
    "            'val_f1': best_metrics['val_f1'],\n",
    "            'best_epoch': best_metrics['epoch'],\n",
    "            'cr': best_metrics['cr']\n",
    "        }\n",
    "        \n",
    "        # Plot and save learning curves for this combination\n",
    "        plot_learning_curves(history, current_params)\n",
    "        \n",
    "        results.append(current_params)\n",
    "        \n",
    "        # Update best overall based on validation F1 score\n",
    "        if current_params['val_f1'] > best_overall['val_f1']:\n",
    "            best_overall['train_loss'] = current_params['train_loss']\n",
    "            best_overall['train_acc'] = current_params['train_acc']\n",
    "            best_overall['val_acc'] = current_params['val_acc']\n",
    "            best_overall['val_f1'] = current_params['val_f1']\n",
    "            best_overall['cr'] = current_params['cr']\n",
    "            best_overall['params'] = current_params\n",
    "            best_overall['model'] = model.state_dict()\n",
    "        \n",
    "        print(\"\\nCurrent combination metrics:\")\n",
    "        print(f\"Train Loss: {current_params['train_loss']:.4f}\")\n",
    "        print(f\"Train Accuracy: {current_params['train_acc']:.4f}\")\n",
    "        print(f\"Val Accuracy: {current_params['val_acc']:.4f}\")\n",
    "        print(f\"Val F1 Score: {current_params['val_f1']:.4f}\")\n",
    "        print(f\"Best Epoch: {current_params['best_epoch']}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(current_params['cr'])\n",
    "\n",
    "\n",
    "        \n",
    "        print(\"\\nBest overall metrics so far:\")\n",
    "        print(f\"Train Loss: {best_overall['train_loss']:.4f}\")\n",
    "        print(f\"Train Accuracy: {best_overall['train_acc']:.4f}\")\n",
    "        print(f\"Val Accuracy: {best_overall['val_acc']:.4f}\")\n",
    "        print(f\"Val F1 Score: {best_overall['val_f1']:.4f}\")\n",
    "        print(f\"Classification report: \\n {best_overall['cr']}\")\n",
    "\n",
    "    return results, best_overall['params'], best_overall['model']\n",
    "\n",
    "# Example usage\n",
    "in_channels = 2\n",
    "out_channels = 2\n",
    "\n",
    "# Perform grid search with 10 epochs warmup\n",
    "results, best_params, best_model = grid_search(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    in_channels, \n",
    "    out_channels,\n",
    "    warmup_epochs=10  # Adjust this value as needed\n",
    ")\n",
    "\n",
    "# Print best parameters and metrics\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(f\"Number of Layers: {best_params['num_layers']}\")\n",
    "print(f\"Hidden Channels: {best_params['hidden_channels']}\")\n",
    "print(f\"Learning Rate: {best_params['learning_rate']}\")\n",
    "print(f\"Training Loss: {best_params['train_loss']:.4f}\")\n",
    "print(f\"Training Accuracy: {best_params['train_acc']:.4f}\")\n",
    "print(f\"Validation Accuracy: {best_params['val_acc']:.4f}\")\n",
    "print(f\"Validation F1 Score: {best_params['val_f1']:.4f}\")\n",
    "print(f\"Best Epoch: {best_params['best_epoch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_layers = 1\n",
    "hidden_channels = 16\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 50\n",
    "\n",
    "num_features = 2\n",
    "num_classes = 2\n",
    "\n",
    "model = GCN(in_channels, hidden_channels, num_layers, out_channels)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "weights = torch.tensor([0.00035, 0.1])\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# Lists to store loss and accuracy values for plotting\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # For data_object in train_dataset:\n",
    "    for i in range(len(train_dataset)):\n",
    "        data_object = train_dataset[i]\n",
    "        out = model(data_object.x, data_object.edge_index)\n",
    "        optimizer.zero_grad()\n",
    "        y = data_object.y.long().squeeze() \n",
    "        loss = criterion(out, y)  # Calculate loss on all nodes\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "        # Compare predictions\n",
    "        pred_train = out.argmax(dim=1)\n",
    "        correct_train += (pred_train == y).sum().item()\n",
    "        total_train += y.numel()\n",
    "\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_losses.append(epoch_loss / len(train_dataset))  # Average loss\n",
    "\n",
    "    # Validating\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(val_dataset)):\n",
    "            data_object = val_dataset[i]\n",
    "            out = model(data_object.x, data_object.edge_index)\n",
    "            y = data_object.y.long().squeeze()\n",
    "\n",
    "            pred_val = (out.argmax(dim=1))\n",
    "            #print(f\"Prediction: {pred_val} \\n\")\n",
    "            correct_val += (pred_val == y).sum().item()\n",
    "            total_val += y.numel()\n",
    "\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, \"\n",
    "            f\"Train Acc: {train_accuracy:.4f}, Validation Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "# Plot the loss and accuracy curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        data_object = test_dataset[i]\n",
    "        out = model(data_object.x, data_object.edge_index)\n",
    "        y = data_object.y.long().squeeze()\n",
    "\n",
    "        pred_test = (out.argmax(dim=1))\n",
    "        #print(f\"Prediction: {pred_val} \\n\")\n",
    "        correct_test += (pred_test == y).sum().item()\n",
    "        total_test += y.numel()\n",
    "\n",
    "test_accuracy = correct_test / total_test\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        data_object = test_dataset[i]\n",
    "        out = model(data_object.x, data_object.edge_index)\n",
    "        y = data_object.y.long().unsqueeze(1)\n",
    "\n",
    "        pred_test = (out.argmax(dim=1))\n",
    "        y_true.extend(y.numpy().flatten().tolist())\n",
    "        y_pred.extend(pred_test.numpy().flatten().tolist())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Calculate classification report (includes precision, recall, F1-score)\n",
    "target_names = ['Not part of path', 'Part of path']  # Adjust class names as needed\n",
    "cr = classification_report(y_true, y_pred, target_names=target_names)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(cr)\n",
    "\n",
    "# Calculate overall accuracy (can cross-check with the report)\n",
    "accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Extract TP, TN, FP, FN for manual metric calculation if needed\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "#Manual calculation of metrics for verification if needed\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize the model\n",
    "num_features = dataset[0].x.shape[1]\n",
    "num_classes = len(set([label.item() for data in data_list for label in data.y]))  # Assuming labels are from 0 to num_classes-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(in_channels=num_features, hidden_channels=16, out_channels=num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize the model\n",
    "num_features = dataset[0].x.shape[1]\n",
    "num_classes = len(set([label.item() for data in data_list for label in data.y]))  # Assuming labels are from 0 to num_classes-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(in_channels=num_features, hidden_channels=16, out_channels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#model = GCN(hidden_channels=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "weights = torch.tensor([0.001, 0.1])\n",
    "criterion = torch.nn.BCELoss(weight=weights)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# Lists to store loss and accuracy values for plotting\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data_object in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data_object.x, data_object.edge_index)\n",
    "        y = data_object.y.float()\n",
    "        loss = criterion(out, target_one_hot)  # Calculate loss on all nodes\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compare predictions for each class, then check if BOTH are correct\n",
    "        correct_predictions = (pred == target_one_hot).all(dim=1)  \n",
    "        correct += correct_predictions.sum().item()\n",
    "        total += data_object.y.size(0)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy = correct / total\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data_object in test_loader:\n",
    "            out = model(data_object.x, data_object.edge_index)\n",
    "            pred = (out > 0.5).float()  # Get binary predictions (0 or 1)\n",
    "\n",
    "            # Convert data_object.y to one-hot for comparison with pred\n",
    "            target_one_hot = data_object.y.long().squeeze(1)  \n",
    "\n",
    "            # Compare predictions for each class, then check if BOTH are correct\n",
    "            correct_predictions = (pred == target_one_hot).all(dim=1)  \n",
    "            correct += correct_predictions.sum().item()\n",
    "            total += data_object.y.size(0)\n",
    "\n",
    "    test_accuracy = correct / total\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Train Acc: {train_accuracy:.4f}, Test Acc: {test_accuracy:.4f}\")\n",
    "\n",
    "# Plot the loss and accuracy curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
